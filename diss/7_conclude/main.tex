\chapter{Follow-up and Future work}\label{chap:discuss}

The work presented here has been and continues 
to be extended in a number of different theoretical 
and empirical directions.
Earlier work has already been leveraged in published work,
and more recent chapters
have led to interesting
continuing avenues of research.

\section{Analyzing Disease Trends in Functional MRI via Covariance Trajectories}

Work in Chapters~\ref{chap:covtraj} and \ref{chap:ott} has been further developed for a number of other applications.
Ideas have contributed
to the understanding and modeling of uncertainty
in recurrent models~\citep{spgru},
and more generally towards efficient
Bayesian methods for deep Monte Carlo methods~\citep{mcreparam}.
Applications based on modeling disease progression
as a function of both static and time-varying 
variables was extended to ``deepify-ing" mixed effects models~\citep{deepmem}.

More directly, the covariance trajectory analysis
methods have been extended 
to the analysis of other Alzheimer's Disease populations~\citep{isbi},
and work on understanding and localizing temporal lobe epilepsy
measured over resting-state functional MRI acquisitions is under review.

\subsection{Brain Network Abnormalities in Alzheimer's Disease}
Rs-fMRI has been shown to be a valuable neuroimaging modality to study the pathophysiological mechanisms and effects of Alzheimer's Disease. 
However, most existing brain network modeling frameworks for rs-fMRI often do not account for the combined statistical and temporal dependencies underlying dynamic functional connectivity (dFC) in a statistically robust manner, 
which may be limiting our understanding of altered brain organization in disease.
To address these issues, in this work we demonstrate that
the covariance trajectory methods above can characterize dFC as covariance trajectories on the Riemannian manifold.

In this follow-up work,
we leverage a different setup of the trajectory analysis in Chapter~\ref{chap:covtraj}. Here,
we have a much larger number of timepoints:
compared to patient site visits,
we have functional MRI measurements
occurring at a rate of approximately once per second for scans ranging from 5 to 10 minutes.
While the methods above can be applied,
the computational cost, while not exponential,
still grows at a rate infeasible 
for this application.

To address this, we construct a ``windowed" approach, where we set specific window sizes and stride lengths such that our trajectory spans the length of the scan,
and smoothly estimates the continuous trajectory through overlapping samples.
We fit the trajectories for each subject and take corresponding means for the likelihood statistics and follow the hypothesis testing as above.
Experimental results demonstrated that the approach is capable of identifying differential effects in large-scale functional networks altered in Alzheimer's Disease in a way that overcomes statistical challenges common with many neuroimaging studies.

\begin{figure}
	\centering
	\includegraphics[width=0.3\columnwidth, trim={11cm 5cm 9cm 5cm}, clip]{7_conclude/figs/Results_Network1.jpg}
	\includegraphics[width=0.3\columnwidth, trim={11cm 5cm 9cm 5cm}, clip]{7_conclude/figs/Results_Network2.jpg}
	\includegraphics[width=0.3\columnwidth, trim={11cm 5cm 9cm 5cm}, clip]{7_conclude/figs/Results_Network3.jpg}
	
	\includegraphics[width=0.3\columnwidth, trim={4cm 1cm 2cm 5cm}, clip]{7_conclude/figs/X1.png}
	\includegraphics[width=0.3\columnwidth, trim={4cm 1cm 2cm 5cm}, clip]{7_conclude/figs/X2.png}
	\includegraphics[width=0.3\columnwidth, trim={4cm 1cm 3cm 5cm}, clip]{7_conclude/figs/X3.png}
	
	\caption[Functional network differences in Alzheimer's patients vs. controls]{Functional networks exhibiting significant first- and second-order group differences with the corresponding estimated null distribution and alternative statistic (red) using our pipeline  (brain visualization from right).}
\end{figure}

\subsection{Characterizing the Epilepsy Connectome}
Building on the developments adapting these methods to functional MRI,
we deploy and extend the windowed-approaches
to the study of temporal-lobe epilepsy (TLE),
where disease signals are known to
cause widespread disruptions in connectivity dynamics within the well-studied epileptogenic network, 
but it is not yet clear if and to what extent other networks are perturbed in TLE.

Experimentally, we demonstrate that the approach identifies distinct subsets of temporally evolving connectivity features that stratify TLE patients and healthy controls, which map to altered connectivity at the network-scale. 

\begin{figure}
	\centering
	\includegraphics[width=0.45\textwidth, trim={2.5cm 0cm 3cm 0cm}]{7_conclude/figs/ProposedMethod_Results1.jpg}
	\includegraphics[width=0.45\textwidth, trim={2.5cm 0cm 4cm 0cm},clip]{7_conclude/figs/ProposedMethod_Results2.jpg}
	\caption[Differences in network connectivities in TLE populations]{Networks exhibiting significant first- and second-order group differences using the proposed method with the corresponding estimated null distribution and alternative statistic: (from left to right) Subcortical, Insular and Frontal Opercular Cortex, Inferior Frontal Cortex, Orbital and Polar Frontal Cortex. S - saggital view, R - visualization from the right, F - visualization from the front. \label{fig:CovTrajResults}}
\end{figure}

\section{Building Plug-and-Play Tools for Discrete Optimal Transport}

The rate of development and research in machine learning and associated applications
continues at its current pace
largely due to 
easily deployable tools that
operate seemlessly with existing workflows.
PyTorch, Tensorflow, and all associated software
packages have enabled this growth.
In fact,
concurrent to this work,
a separate group had identified 
similar insights to ours,
and was similarly reviewed and published
with great interest at the same conference~\citep{just2023lava}.
While there have been significant 
developments in Optimal Transport
and its associated 
uses in deep learning,
turnkey tools remain somewhat lacking
for a number of reasons,
as described in Chapter~\ref{chap:demd}.

Building upon the theoretical
efficiencies of the $d$-EMD solver
and minimizer,
we are developing
a plug-in for the Python Optimal Transport library,
with the goal of enabling
optimal transport researchers to 
more easily develop methods
for both pure transportation problems,
as well as methods that incorporate
with automatic differentiation pipelines.
With the ability to solve larger-scale 
problems efficiently,
users can more easily solve 
problems with high-dimensional data
that would otherwise be infeasible
with existing off-the-shelf solvers.

As noted,
the efficient multi-marginal solution
opens the door to a large number 
of domains unstudied due to computational cost.
With approachable open-source code
we hope to expand the tools described
beyond one-dimensional distributions
to problems in computer vision,
both over two dimensional image spaces
as well as beyond.
New computational bottlenecks may arise
as the distributions become
higher-order tensors, which 
may themselves lead to 
the need for new technical
insight.

Building upon the applications in fairness
and the ideas related to subgroup fairness
mentioned at the end of Chapter~\ref{chap:demd},
we hope to specifically
develop and merge existing fairness
software stacks with our tools.
Theoretically, subgroup fairness implies
particular relationships among distributions,
and as such interesting algorithmic
and computational tools may be enabled
under assumptions typical in subgroup settings.


\section{Interpretability and Conditional Independence In Deep Latent Spaces}\label{sec:latents}
\todo{ongoing/future work on latent spaces and condindep}
Work in unlearning in Chapter~\ref{chap:lcodec} is relatively nascent,
but excitement in the field is growing
and a number of works have been motivated
by recent successes.
Methods for directly measuring, and perhaps
even promoting or reducing conditional
independence are beginning to be explored.
Building upon these ideas,
we briefly describe a particular 
direction of interest, motivated
by the recent large successes of large language models.



conditional independence
interpretability
mobiledets
disentangling latent reps


\subsection{A Final Note}
state of ML/AI, language models