\section{Deep Unlearning via L-FOCI Hessians}
%\section{Deep Unlearning via L-FOCI Hessians}
\label{sec:deepunlearn}

%As mentioned in Remark~\ref{rem:sens}, 
Our input samples to scrub $z^\prime$ are not random variables for which we have samples or distributional assumptions, nor are our parameters. In this case, 
% As mentioned in Remark~\ref{rem:sens},
a perturbation-based scheme may be useful when attempting to generate samples for unknown distributions.
% We take advantage of this directly to generate samples for any model context.

Considering Assump.~\ref{assum:sub}, when only some parameters are useful for the final outcome on an input sample $z^\prime \in S$, the effect of those parameters can be measured through activations due to the forward pass of a model. We estimate the conditional independence test in \eqref{eq:assum} through activations as
\begin{align}
    f(z^\prime) \bot a_{\Theta\setminus P}^* | a_P^*,
\end{align}
where $a_P$ for some parameter subset $P \subseteq \Theta$ is defined as the linear activations generated by the forward pass through the model.
This formulation relates to a generalized version of the solution in \S3 of \cite{bullseye}, where conditional mutual information is estimated via feature mappings.

As an example, if a network has linear layers $\cL$, a simple linear layer $l \in \cL$ with parameters $w_l \in \RR^{a \times b}$ would have activations $a_l \in \RR^b$, with $a_l = w_l a_{l-1}$. For each entry $a_{l,j}$ in the vector $a_l$, the associated parameters in the layer are $w_l[:,j]$. Thus, we break up the network into influential \textit{slices.} These slices can be seen as a finer view of the parameter space compared to typical layerwise selection, but coarser than a fully discrete one. Next, $\cL$ now refers to the collection of these slices, with a specific slice as $l$.

The tuple of variables we need samples from is now
\begin{align}
    \{a_1, \ldots a_{|\cL|}, \cL(z^\prime)\}
\end{align}
We can obtain samples from this set by perturbing the input and consecutively collecting activations along all weight slices during the computation of the loss. For a particular perturbation $\xi^j \sim N(0,\sigma^2)$,
\begin{align}
    x_i^j = x_i + \xi^j; \quad
    l^j, a_L^j = \{l(x_i^j), a_1^j, \ldots a_{|\cL|}^j\}
\end{align}
The tuples $(l^j, a_L^j)$ serve as samples for our conditional independence test, 
\begin{align}
    (P \subseteq \Theta) &= \mbox{L-FOCI}((l^j, a_\cL^j)_{j=1}^m)
\end{align}
for $J:=\{j \in 1,\ldots,m\}$ perturbations (see Figure~\ref{fig:lfoci}).

In Alg.~\ref{alg:blockunlearn}, the activations are collected using hooks within the forward pass. 
First, gradients at the last and penultimate epoch for full training are stored during the original training pass. Given a sample to unlearn, we compute L-FOCI over the perturbed activations and losses generated by the forward pass, and identify which parameter sets will be updated. We compute the approximate Hessian over these parameters via finite differences for both the full model and for the model only over the sample of interest. Finally, we apply the blockwise Newton update to the subset of parameters as in \eqref{eq:unlearn} with appropriate DP noise as in \cite{sekhari2021remember}.
\begin{algorithm}
\small
\SetAlgoLined
\KwData{A trained model $\hat{w}$, gradient vectors $\nabla_1 F(\hat{w}), \nabla_2 F(\hat{w})$, sample $z' \in \cS$ to unlearn.}
\KwResult{model $w'$ with $z'$ removed.}
1. \For{$j \in \{1,\ldots, m\}$ perturbations}{
    $\xi^j \sim N(0,\sigma^2)$ \\
    $z^{\prime,j} = z^\prime + \xi^j$ \\
    $l^j, a^j = f(z^{\prime,j})$ \\
    % \eIf{$T(z',w_{\setminus P}, w_{P \cup p}) < 0$}{break}{Append $P = P \cup p$}
}
2. Compute $P* = \mbox{L-FOCI}(l^J, a^J)$. \\
3. Compute $\nabla^2_{P} F(\hat{w}, z^\prime)$ via finite differences. \\
4. Update:
\begin{align}
    H_P' &= \frac{1}{n-1}\left(n \nabla^2_{P} F(\hat{w}) - \nabla^2_{P} f(\hat{w}, z')\right) \\
    w_{P}' &= \hat{w}_{P} + \frac{1}{n-1}H_{P}'^{-1} \nabla f(\hat{w}, z')_{P} \\
    w'_{\Theta\setminus P} &= \hat{w}_{\Theta\setminus P}
\end{align}
 \caption{\label{alg:blockunlearn} Unlearning via Conditional Dependence Block Selection}
\end{algorithm}

\paragraph{Computational Gains.}
A direct observation is that now we are doing sampling, which adds a linear computational load.
However, directly updating all parameters requires $O(d^3)$ computation due to matrix inversion, while this procedure requires $O(md + dm\log m + p^3)$, for the forward passes, FOCI algorithm, and subsequent subsetted matrix inversion. For any reasonable setting, we have $p \ll d$, and so this clearly offers significant practical advantages.








% Based on the above observations we make the following assumption for samples in the training set:
% \begin{assumption}\label{assum:sub}
% For all subsets of samples $S \subset D$, there exists a subset of the model parameters $P \subset \Theta$ such that 
% \begin{align}
%     L(S) \bot w_{\Theta\setminus P}^* | w_{P}^*
% \end{align}
% \end{assumption}

% \begin{assumption}
% \begin{align}
%     \forall S \sim \mathcal{P}(\mathcal{X}, \mathcal{Y}) \quad \exists T \subset L \\
%     s.t., \quad \mathcal{L}(S) \bot w^{*}_{L\setminus T} | w^{*}_T
% \end{align}
% \end{assumption}
% where, $S$ is the set of data points sampled from the joint training distribution of $\mathcal{P}(\mathcal{X}, \mathcal{Y})$, $w^*$ are the model parameters for a trained converged model, $L$ is the set of all layers (filters), $T$ is the subset of all layers which we will later tie to our selection algorithm. $\mathcal{L}$ is the loss function. 
% Note: $S$ can be a singleton containing only one data point to be removed. It is most beneficial to think of $S$ as a set of data points belonging to a particular class. 

% Input perturbation to get samples for FOCI computation: Given a data point $(x_k, y_k)$ from the training set $D$ we want to remove it. So, we perturb the input by adding small amount of Gaussian noise to generate samples for it. We have,

% \begin{align}
%     (x_k, y_k) \in D \xrightarrow[\text{perturbation}]{\text{input}} \{(x_k +g_k, y_k) | g_k \sim \mathcal{N}(0,1)\} = S_k
% \end{align}
% So, $S_k$ becomes our set S in \textbf{Assumption 1}. We generate sample for FOCI of the form $(\mathcal{L}(S_{k_i}), w^*(S_{k_i}))$; where $S_{k_i}$ is the $i$th perturbation of $x_k$ from set $S_k$ and $\mathcal{L}(S_{k_i})$ is the loss for the corresponding perturbation. 
% After this $FOCI({(\mathcal{L}(S_{k_i}), w^*(S_{k_i})) | S_{k_i} \in S_k})$ gives us the required $T \subset L$ selection; i.e. selects $T$ out of $L$ layers in the model following \textbf{Assumption 1}. 

% For the samples in the training set:
% \begin{assumption}
% For all subsets of samples $S \subset D$, there exists a subset of the model parameters $P \subset \Theta$ such that 
% \begin{align}
%     L(S) \bot w_{\Theta\setminus P}^* | w_{P}^*
% \end{align}
% \end{assumption}



% \begin{theorem}
% The change in the activation of a layer $l_{i+1}$ after an update to a previous one is bounded as:
% \begin{align}
%     |l_{i+1}(\tilde{a}_i) - l_{i+1}(a_i)| \leq \frac{2ML^2m^2}{\lambda^3 n^2}
% \end{align}
% \end{theorem}
% \begin{proof}
% Let the output of the previous layer be given as $w_l * a_{l-1}$, and the scrubbed output be $\tilde{w}_l * a_{l-1}$. Then we can Taylor expand around the output of the next layer for the previous  $l_{i+1}(\tilde{w}_l a_{l-1})$:
% \begin{align}
%     l_{i+1}(\tilde{w}_l a_{l-1}) &= l_{i+1}((w_l + \Delta) a_{l-1}) \\
%     &= l_{i+1}(w_l a_{l-1}) + \nabla l_{i+1}(w_l a_{l-1}) \Delta + O(\Delta^2)
% \end{align}
% where $\Delta = \tilde{w}_l - w^*_l$, or the Sekhari update:
% \begin{align}
%     \Delta = \frac{1}{n+1}H^{-1} \nabla f(x_r).
% \end{align}
% The first-order term vanishes, because the gradient at the original point $w_l$ is 0 given that we've trained

% %For a specific parameter layer, the linear assumption allows us to use a form of convexity (?). 
% From Lemma 6 in Appendix C.1 of  \cite{sekhari2021remember}, we have that 
% \begin{align}
%     |w^* - \tilde{w}| \leq \frac{2mL}{\lambda n},
% \end{align}
% so 
% \end{proof}

% \begin{theorem}
% Residual Gradient norm
% \end{theorem}
% \begin{proof}

% \end{proof}