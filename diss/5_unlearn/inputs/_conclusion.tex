\section{Conclusion}
Our selection scheme identifies a subset of parameters to update and significantly reduces compute requirements for standard Hessian unlearning. 
%For unlearning, While retraining of small models is a possibility, but unavailability of full training set and for larger models, unlearning is desired.
For smaller networks with a large number of removals, retraining may be effective, but when full training sets are not available or retraining is costly, unlearning in some form is needed. 
We show the ability to approximately unlearn for large models prevalent in vision, a capability that has not so far been demonstrated.  

\paragraph{Social Impact.} 
%This work 
%is motivated by social considerations of 
%modern ML/Vision models. 
Indiscriminate use of personal data in training 
large AI models is ethically questionable 
and sometimes illegal. We need mechanisms to ensure that AI models operate 
within boundaries specified by society 
and legal guardrails. As opt-out laws get 
implemented, compliance on the service-provider end will entail costs. 
While our contributions cannot guarantee perfect forgetting, with additional 
validation they can become a part of a suite of methods for unlearning. 

\paragraph{Acknowledgments.}
This work was supported by grants from the National Institutes of Health numbered RF1AG059312, RF1AG062336 and RF1AG059869, NSF award CCF 1918211 and funds from the American Family Insurance Data Science Institute at UW-Madison. Sathya Ravi was supported by UIC-ICR start-up funds.

% \section*{Acknowledgements}
% This work was supported by funding su