Our main statistical testing framework, to be described shortly, needs an efficient means for calculating a ``trajectory'' of the feature-by-feature interaction graphs over time
for the given longitudinal data. We now describe a scheme which offers this capability. 
Let $X_t \in \RR^{n_t,p}$ be the design matrix of all $n_t$ samples at time $t$, where $t \in \{1,\ldots,T\}$, and $T$ is the total number of distinct timepoints.
We wish to capture the trends in the relationships between the features as a function of $t$. 
To evaluate the groupwise differences in changes of such interactions, we make use of the fact
that these interactions are commonly captured by correlation or conditional independence, represented by the covariance matrix (with normalized features)
and the precision matrix (the inverse of covariance matrix).

Here we simply use the covariance matrix for each timepoint $t$ to denote the interaction between features, 
$C_t = cov(X_t)$. 
Our goal now is to estimate the parameters of the function, $t \to C_t$. 
We may vectorize the covariance matrix and apply a linear model; its parameters
will give the trajectory in ``vectorized covariance space'' as we scan through $t$. 
But these predictions are {\em not} guaranteed to be valid  $\SPD$ matrices and even if a projection is performed to obtain a covariance estimate, distortions introduced by the process may be significant \citep{fletcher2013geodesic}. 
It is well known that classical vector space models tend to be suboptimal 
in the manifold setting (covariance matrices live on the $\SPD$ manifold)
since they use Euclidean metrics which are defined in the ambient space. For manifold-valued data, Riemannian metrics are shown to be superior in many applications 
\citep{fletcher2007riemannian,banerjee2015nonlinear,jayasumanakernel,tuzel2007human}, 
and are increasingly being deployed in machine learning and statistics. 
We will utilize an appropriate statistical model informed by the manifold-structure of the data and 
then derive a hypothesis 
testing procedure to detect groupwise difference in the changes of interactions between features in longitudinal analysis.
%\subsection{Riemannian Geometry}
% Let $\Mc$ be a \textit{differentiable (smooth) manifold} in arbitrary dimensions. 
%A differentiable manifold $\Mc$ is a topological space that is locally similar to Euclidean space and has a globally defined differential structure. 
% A \textit{Riemannian manifold} is a differentiable manifold $\Mc$ equipped with a smoothly varying inner product.
% The \textit{geodesic curve} is the locally shortest path, analogous to straight lines in $\mathcal{R}^{p}$ --- this geodesic curve will be the object that defines the trajectory of our covariance matrices in $\SPD$ space. 
% Unlike the Euclidean space, note that there may exist multiple geodesic curves between two points on a curved manifold. 
%So, the \textit{geodesic distance} between two points on $\Mc$ is defined as the length of the {\em shortest} geodesic curve connecting two points.
%The geodesic distance helps in measuring the error of our trajectory estimation (analogous to a Frobenius or $\ell_2$ norm based loss in the Euclidean setting).
%The geodesic curve from $y_i$ to $y_j$  is parameterized by a tangent vector in the tangent space anchored at $y_i$ with an exponential map $\EXP(y_i,\cdot ): T_{y_i}\Mc \rightarrow \Mc$. 
%The inverse of the exponential map is the logarithm map, $\LOG(y_i,\cdot):\Mc \rightarrow T_{y_i}\Mc$. These two operations move us back and forth between the manifold and the tangent space. 
%Separate from the above notation, matrix exponential (and logarithm) are simply $\exp(\cdot)$ (and $\log(\cdot)$). 
%Finally, \textit{parallel transport} is a generalized parallel translation on manifolds. Given a differentiable curve $\gamma : \mathcal{I} \rightarrow  \Mc$, where $\mathcal{I}$ is an open interval, 
%the parallel transport of $v_0 \in T_{\gamma(t_0)}\Mc$ along curve $\gamma$ can be interpreted as the parallel translation of $v_0$ on the manifold preserving its length and the angle between $v (t)$ and $\gamma$. 
%The parallel transport of $v$ from $y$ to $y'$ is $\Gamma_{y\rightarrow y'}v$.