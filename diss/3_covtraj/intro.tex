As described in the previous chapter, a number of methods have been extensively studied for 
the sparse recovery of graphical models
with various assumptions on collected data.
% {\em Coupled and Temporal Graphical Models.} 
%In various situations,
Often, data come from two (or more) disparate sources or multiple timepoints.
%, where we seek to estimate 
%a model for each source {\em independently}.
%When the sources share the same variables as well as the
%nd a non-trivial portion 
%of the
%dependency structure, we may decide to pool the data together and estimate a single model in an effort to boost statistical power. However, 
%such an approach invariably masks the heterogeneity in the data-set sources \cite{friston2011functional}. While we want 
%to preserve the common structure, ideally, we also wish to allow for differences among the 
%sources. Consequently, w
Proposals in the literature have 
described strategies for linking the sparsity patterns of multiple graphical models, e.g., using a fused lasso 
penalty \citep{danaher2014joint,yang2015fused}. Observe that 
%these ideas assume that the two (or more) models share a similar structure; 
if the data sources correspond to {\em longitudinal} acquisitions, we should expect 
the `structure' to gradually evolve.
%, which is discouraged in direct applications of the above idea. 
%in the case where the model is changing such a construction would not allow for identification of the evolving graph structure. 
Several authors have offered generalizations to address this problem: \cite{zhou2010time} removes the assumption
that each graph is independent and structurally `close'.
Instead, \cite{zhou2010time} can be thought of as a growth model \citep{mcardle2000introduction} defined on these structures: they show how non-identically distributed graphs can be learned over time. 
Recently, the nonparametric procedure in \cite{qiu2015joint} extends these ideas
%via means
to handle multiple sources, each with multiple samples.

The ideas in the literature so far to ``couple'' multiple graphical model estimation modules are mostly nonparametric. 
While such formulations offer benefits, in many estimation problems, 
parametric models may 
%require fewer samples (better convergence rates) and possibly, 
be more convenient for downstream statistical analysis,
particularly for hypothesis testing \citep{hardle1993comparing,geer2000empirical,roehrig1988conditions}.
Given that the topic of \textit{coupled} graphical models, by itself, is fairly recent, algorithms for {\em parametric estimation} of 
temporal or coupled Gaussian graphical models have not yet been heavily studied. 
%Part of the reason is the difficulty of 
This will involve parameterizing {\em trends} in the highly structured nature of the `response' variable ($\SPD$ matrices). 
%In contrast, w
More recently, we find that parametric formulations for manifold-valued data {\em have} been proposed \citep{hjkimcvpr2014,cornea2016regression}. %, albeit only in the 
%context of regression models and dictionary learning \cite{xie2013nonlinear}. 
%This result is relevant --- b
Because $\SPD$ matrices form a Riemannian manifold, algorithms
that estimate a parametric model respecting the underlying Riemannian metric are more suitable in many applications,
as opposed to assuming a Euclidean metric 
on positively or negatively curved spaces \citep{xie2010statistical, fletcher2007riemannian, jayasumanakernel}. We will make a few simple modifications 
(for efficiency purposes) to such algorithms and make use of the estimated parameters for follow-up analysis.

%Unfortunately, their deployment for the $\SPD$ may not always be trivial.

\paragraph{Finding Group-wise Differences.} Assuming that we have a black-box procedure to estimate a parametric model on the $\SPD$ manifold available, 
in many tasks, such an estimation is merely a segue to other analyses designed to answer scientifically meaningful questions. 
For example, we are often interested in asking whether the temporally coupled model estimated using the procedure above differs 
in meaningful ways {\em across} groups induced by a stratification or dichotomous variable (e.g., gender or disease). For instance, is the `slope' in a structured response space statistically different 
across education level or body mass index? 
%in if this model differs significantly across two groups.
While existing work in graphical model estimation is mature, the literature describing hypothesis tests in this
regime \citep{diffnet,belilovsky2015hypothesis}
is relatively nascent.
%When considering a single graphical model for each group, \cite{diffnet} propose a framework for two sample testing to discover differences in biological network structures.
%However, to the best of our knowledge no literature exists describing a testing framework for temporal graphical models.
%In this paper we propose a method for evaluating this group difference temporally.
Given that such questions are simpler to answer with alternative schemes (with assumptions on the distributional properties of the data), e.g., structural equation modeling, 
latent growth models and so on \citep{ullman2003structural, mcardle2000introduction}, it seems that 
the unavailability of such tools is limiting the adoption of such ideas in a broader 
cross-section of science. Here we will seek to address this gap. 

\paragraph{Needles in Temporal Haystacks.} If we temporarily set aside the potential value of a hypothesis test framework for temporal 
trajectories in graphical models, we see that
from an operational viewpoint, such procedures are most effective when a practitioner already has a precise scientific question in mind. In reality, however, 
many data analysis tools are deployed for exploratory analyses to inform an investigator as to which questions to ask. 
Being able to ``localize'' which parts of the model are different across groups over the entire time window can be very valuable. This ability actually 
benefits statistical power as well. Notice that when the stratified groups are not very different 
to begin with, e.g., healthy individuals with presence or absence of a genetic mutation, the
effect sizes are likely to be poor.
Here, while the trends identified on the {\em full} precision matrix may still be different (i.e., there may be a {\em real} signal 
associated with a grouping variable), 
they may not be strong enough to survive significance thresholds. Ideally, what we need here are analogs of widely used ``scan statistics'' 
for our hypothesis testing formulations for temporal graphical models --- to identify which {\em parts of the signal} are promising. 
Then, even if only a small subset of 
features were different across groups over all time,
%(whereas the complement of this sub-graph were similar, i.e., not different)
we may be able to identify these differential effects efficiently. This benefits Type 2 error, 
provides a practical turnkey product for an experimental scientist, and makes up the key technical results of our work.

%motivation for our selection, cost etc.
%A second key issue we aim to address is that of feature selection. In many medical regimes, the true indicators and dependencies among measured features is unknown. In most analyses feature selection is done manually, generally by the researcher. Structural equation modeling (SEM) in particular is a popular tool which requires the user to choose the features as input for analysis. The first component of SEM requires the \textit{structural model} be specified, that the dependences we wish to determine significant are explicitly stated. Quantitative approaches for feature selection  (cite) have been looked at in machine learning. (elaborate)... In the case of image analysis, scan statistics have been used as a measure to detect regions of high correlation between images (cite what Ming cites). These scan statistics, however, require a selection of a subregion of the image or some strong heuristic to make the problem of searching over all possible window sizes tractable. Recently (ming paper) were able to polynomially bound the number of regions needed to detect highly correlated regions with high probability. Motivated by their work, we attempt to solve a parallel problem. In the case of feature selection among high-dimensional covariance matrices, we aim to identify a subset of features such that the evolution of the correlation matrix is significantly different among two groups.

\input{3_covtraj/grenander.tex}

Concurrent to this work, \cite{su2014statistical,zhang2018rate} have developed similar methods of analyzing the statistical properties of trajectories on the $\SPD(n)$ manifold via the transported square-root vector field. While here we focus on a simple approach to enable localization, these developments can be incorporated into this construction.

Briefly, we provide \textbf{(i)} a simple and efficient parametric procedure for modeling temporally evolving graphical models, \textbf{(ii)} a 
hypothesis test for identifying differences between group-wise estimated models, and \textbf{(iii)} a scan
algorithm to identify {\em those subsets of the features which contribute to the group-wise differences}.
Together, these ideas offer a framework for identifying group-wise differences in temporally coupled graphical models.
%We next cover preliminary concepts, we define our model and present an algorithm, followed by experimental results on both simulated data and neuroimaging data 
%acquired from 
From the experimental perspective, we find scientifically plausible results on 
a unique longitudinally tracked cohort of middle-aged (and young elderly) persons at risk for Alzheimer's disease due to family history, 
but who are otherwise completely cognitively healthy.

The rest of this chapter is organized as follows. In Section \ref{sec:mglm} we present an efficient manifold regression procedure for 
modeling covariance trajectories, which serves as a blackbox module in our hypothesis testing framework. 
In Section \ref{sec:hyp-test}, we define our main hypothesis test for group difference analysis over covariance trajectories. 
In Section \ref{sec:loc}, we present a set of technical results describing our localization procedure based on scan statistics, 
as well as derive suitable size corrections to compare across feature subsets. Sections \ref{sec:loceval}, \ref{sec:pipeval}, and \ref{sec:wrap} conclude with
empirical evaluations of our model on synthetic data, various types of demographics/behavior data collected longitudinally 
in the United States from publicly available resources, and finally, our 
analysis on a unique longitudinal dataset (followed from 2001 to 2017) from a preclinical Alzheimer's disease study involving approximately 1500 individuals.
